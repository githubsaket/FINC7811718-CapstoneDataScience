{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine based feature selection predict stock direction 2014-2015 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxHymRJ_qWCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ccf3dc-74e3-456f-b3be-55238564cf3a"
      },
      "source": [
        "# Library loads\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from numpy import random\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import Normalizer\n",
        "#from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score, mean_squared_error,mean_absolute_error, roc_curve, classification_report, auc)\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For creating plots using data \n",
        "'''\n",
        "import seaborn as sns\n",
        "import plotly\n",
        "from plotly import __version__\n",
        "print(plotly.__version__)\n",
        "import cufflinks as cf\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected = True)\n",
        "cf.go_offline()\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'colab'\n",
        "'''\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA7DKF8vNtFu",
        "outputId": "31b5cad3-1d07-4c5a-8ba7-7718b2870c16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6EwaDP-NHtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c61610-ee4b-426f-f786-633dcf5ab1b3"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "seed=1\n",
        "\n",
        "data_2014 = pd.read_csv('/content/drive/My Drive/Data/2014_Financial_Data.csv', header=0)\n",
        "data_2015 = pd.read_csv('/content/drive/My Drive/Data/2015_Financial_Data.csv', header=0)\n",
        "data_2016 = pd.read_csv('/content/drive/My Drive/Data/2016_Financial_Data.csv', header=0)\n",
        "data_2017 = pd.read_csv('/content/drive/My Drive/Data/2017_Financial_Data.csv', header=0)\n",
        "data_2018 = pd.read_csv('/content/drive/My Drive/Data/2018_Financial_Data.csv', header=0)\n",
        "#print(data_2014.shape, data_2015.shape, data_2016.shape, data_2017.shape)\n",
        "#filename='/content/drive/My Drive/Data/2018_Financial_Data.csv'\n",
        "#print(filename)\n",
        "\n",
        "#data=pd.read_csv(filename, header=0)\n",
        "data_all=pd.concat([data_2014,data_2015,data_2016,data_2017])\n",
        "\n",
        "data = pd.DataFrame(data_2014)\n",
        "data_2015 =pd.DataFrame(data_2015)\n",
        "data.shape, data_2015.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3808, 225), (4120, 225))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2XrqynvP0uD"
      },
      "source": [
        "**Creating function for Evaluation using Accuracy, Precision**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzLlwqlKPBtv",
        "outputId": "3e15def0-0753-48b9-bcc2-cc5a937709a4"
      },
      "source": [
        "print(data.iloc[:, -1].unique().size)\n",
        "\n",
        "if data.iloc[:, -1].unique().size==2:\n",
        "    def evaluate(y_test, y_pred, y_scores):\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='binary', pos_label=1) #labels=np.unique(y_pred))\n",
        "        recall = recall_score(y_test, y_pred, average='binary', pos_label=1) #labels=np.unique(y_pred))\n",
        "        f1 = f1_score(y_test, y_pred, average='binary', pos_label=1) #labels=np.unique(y_pred))\n",
        "        auc = roc_auc_score(y_test, y_scores)\n",
        "        return [accuracy, precision, recall, f1, auc]\n",
        "else:\n",
        "\n",
        "    def evaluate(y_test, y_pred, y_scores):\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', pos_label=1) #labels=np.unique(y_pred))\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', pos_label=1) #labels=np.unique(y_pred))\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', pos_label=1) #labels=np.unique(y_pred))\n",
        "\t\t\t\t#metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\t\t \n",
        "\n",
        "        auc = roc_auc_score(y_test, y_scores)\n",
        "        return [accuracy, precision, recall, f1, auc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4QXzL7Urd5"
      },
      "source": [
        "data.fillna(0, inplace=True)\n",
        "data_2015.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boZVP67kQNtp"
      },
      "source": [
        "**Replace all NaN with 0 and blanks with 0 Enable coding to convert Sector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYSnth1mPznL",
        "outputId": "5225fad4-80fe-4db9-e66a-00d70877da77"
      },
      "source": [
        "#data.fillna(0, inplace=True)\n",
        "#data_2016.fillna(0, inplace=True)\n",
        "\n",
        "# Categorical boolean mask\n",
        "categorical_feature_mask = data.dtypes==object\n",
        "# filter categorical columns using mask and turn it into a list\n",
        "categorical_cols = data.columns[categorical_feature_mask].tolist()\n",
        "#categorical_cols1 = data_2018.columns[categorical_feature_mask].tolist()\n",
        "\n",
        "print(categorical_cols)\n",
        "#Use LabelEncoder() to transfer categorical data to numurical data\n",
        "le=LabelEncoder()\n",
        "print(len(categorical_cols))\n",
        "if len(categorical_cols)!=0:\n",
        "    data[categorical_cols] = data[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "    #data_2018[categorical_cols] = data_2018[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "#data[categorical_cols].head(5)\n",
        "#data_2018[categorical_cols1].head(5)\n",
        "\n",
        "data=np.array(data)\n",
        "data_2015=np.array(data_2015)\n",
        "#If first column is ID, then manuly removed from the dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Unnamed: 0', 'Sector']\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A05cfnffPBZm"
      },
      "source": [
        "**Define Train and Test data and Label data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqsD2J52QpzV"
      },
      "source": [
        "#X,y=data[:,1:-4], data[:, -1]\n",
        "#X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.20, random_state=seed)\n",
        "#y_train=y_train.astype(int)\n",
        "\n",
        "X_train,y_train=data[:,1:-4], data[:, -1]\n",
        "X_test,y_test=data_2015[:,1:-4], data_2015[:, -1]\n",
        "#ros = RandomOverSampler(random_state=0)\n",
        "\n",
        "#X_train, y_train = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train2 = scaler.transform(X_train)\n",
        "X_test2 = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "traindata = np.array(X_train2)\n",
        "trainlabel = np.array(y_train)\n",
        "\n",
        "testdata = np.array(X_test2)\n",
        "testlabel = np.array(y_test)\n",
        "\n",
        "traindata=traindata.astype(float)\n",
        "trainlabel=trainlabel.astype(int)\n",
        "testdata=testdata.astype(float)\n",
        "testlabel = testlabel.astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTQSd3s-T8y9"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkHjU8z6T9om"
      },
      "source": [
        "def MLP(X_train,y_train,X_test,y_test):\n",
        "    clf = MLPClassifier(solver='lbfgs', activation= 'relu', alpha=1e-5,hidden_layer_sizes=(10, 5), random_state=seed)\n",
        "    \n",
        "    l=X_train[0].size\n",
        "    lr = np.logspace(-5,-1, 5)\n",
        "    #print(lr)\n",
        "    #print(X_train[0].size)\n",
        "    hz=[(10, 5),(10,5,3)]\n",
        "    param_grid = {'alpha': lr,'hidden_layer_sizes':hz}\n",
        "\n",
        "    gridcv = sklearn.model_selection.GridSearchCV(clf, param_grid, verbose=1, cv=3)\n",
        "    gridcv.fit(X_train, y_train)\n",
        "\t\t\t\t\t \n",
        "\n",
        "    gridcv = gridcv.fit(X_train,y_train)\n",
        "    y_pred = gridcv.best_estimator_.predict(X_test)\n",
        "    y_scores = gridcv.best_estimator_.predict_proba(X_test)[:,1]\n",
        "\n",
        "    print(\"best parameters:\", gridcv.best_params_)\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedMLP.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duLuPzLV2F3o"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWRkhtH7ULzV"
      },
      "source": [
        "def LogisticRegression(X_train,y_train,X_test,y_test):\n",
        "    clf = sklearn.linear_model.LogisticRegression(random_state=seed, solver='lbfgs')\n",
        "    clf = clf.fit(X_train,y_train)\n",
        "\t\t\t\t\t\t\t\t   \n",
        "\t\t\t\t\t \n",
        "\t\t\t\t\t\t\t \n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_scores = clf.predict_proba(X_test)[:,1]\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedLR.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uvGKFbTUSPV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgdXwf9EUR41"
      },
      "source": [
        "def CART(X_train,y_train,X_test,y_test):\n",
        "   # clf = tree.DecisionTreeClassifier(max_depth=5)\n",
        "   # clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=5,min_samples_leaf=5)\n",
        "\n",
        "    clf = tree.DecisionTreeClassifier( random_state=seed)\n",
        "\n",
        "    md=np.arange(1,50,10)\n",
        "    param_grid = {'max_depth': md}\n",
        "\t\t\t\t\t \n",
        "\t\t\t\t\t\t\t \n",
        "\n",
        "    gridcv = sklearn.model_selection.GridSearchCV(clf, param_grid, verbose=1, cv=3)\n",
        "    gridcv.fit(X_train, y_train)\n",
        "\n",
        "    #clf = clf.fit(X_train,y_train)\n",
        "    y_pred = gridcv.best_estimator_.predict(X_test)\n",
        "    y_scores = gridcv.best_estimator_.predict_proba(X_test)[:,1]\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedDTbase.txt', y_pred, fmt='%01d')\n",
        "    print(\"best parameters:\", gridcv.best_params_)\n",
        "    #tree.plot_tree(clf.fit(X_train,y_train))\n",
        "    #tree.export_graphviz()\n",
        "    #dot_data = tree.export_graphviz(clf, out_file=None)\n",
        "    #graph = graphviz.Source(dot_data)\n",
        "    #graph.render(\"tree\")\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2tFYWqVURrt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_T5G3TBUot0"
      },
      "source": [
        "#randomforest\n",
        "\n",
        "def RandomForest(X_train,y_train,X_test,y_test):\n",
        "    clf = ensemble.RandomForestClassifier(max_features=None,random_state=seed)\n",
        "\n",
        "    md = np.arange(1, 50, 10)\n",
        "    ne = np.arange(1, 50, 10)\n",
        "    param_grid = {'max_depth': md,'n_estimators':ne}\n",
        "\t\t\t\t\t \n",
        "\t\t\t\t\t\t\t \n",
        "\n",
        "    gridcv = sklearn.model_selection.GridSearchCV(clf, param_grid, verbose=1, cv=3)\n",
        "    gridcv.fit(X_train, y_train)\n",
        "\n",
        "    gridcv = gridcv.fit(X_train,y_train)\n",
        "    y_pred = gridcv.best_estimator_.predict(X_test)\n",
        "    y_scores = gridcv.best_estimator_.predict_proba(X_test)[:,1]\n",
        "    print(\"best parameters:\", gridcv.best_params_)\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedRFbase.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phyEqFDUtJk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NJ_AZfRogET"
      },
      "source": [
        "def svm_one_class(X_train,y_train,X_test,y_test):\n",
        "    _train = preprocessing.normalize(X_train, norm='l2')\n",
        "    _test = preprocessing.normalize(X_test, norm='l2')\n",
        "    lin_clf = svm.LinearSVC()\n",
        "    lin_clf.fit(X_train, y_train)\n",
        "    LinearSVC(C=1000, class_weight=None, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
        "     multi_class='ovr', penalty='l2', random_state=seed, tol=0.0001,\n",
        "     verbose=0)\n",
        "    y_pred = lin_clf.predict(X_test)\n",
        "    y_scores = lin_clf.decision_function(X_test)\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedSVMbase.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4uX3_J1Ut4k"
      },
      "source": [
        "def SVM(X_train,y_train,X_test,y_test):\n",
        "\t\n",
        "    svm = sklearn.svm.SVC(kernel='rbf')\n",
        "    C_grid = np.logspace(0, 3, 4)\n",
        "    gamma_grid = np.logspace(-2, 1, 4)\n",
        "    param_grid = {'C': C_grid, 'gamma': gamma_grid}\n",
        "    gridcv = sklearn.model_selection.GridSearchCV(svm, param_grid, verbose=1, cv=3)\n",
        "    gridcv.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = gridcv.best_estimator_.predict(X_test)\n",
        "    y_scores = gridcv.best_estimator_.decision_function(X_test)\n",
        "    print(\"best parameters:\", gridcv.best_params_)\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedSVMNormbase.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vNYdJxjU-r0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smHrLrvaU-Jl"
      },
      "source": [
        "def Gaussian_NB(X_train,y_train,X_test,y_test):\n",
        "    gnb = GaussianNB()\n",
        "\t\t   \n",
        "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        "\t\t\t\t\t\t\t \n",
        "\n",
        "\t\t\t\t\t\t\t\t\n",
        "    y_scores  = gnb.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
        "\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedNBbase.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPMwfBxoL9ci"
      },
      "source": [
        "def kNN(X_train,y_train,X_test,y_test):\n",
        "    clf = KNeighborsClassifier()\n",
        "    #n_neighbors=5\n",
        "    nn=np.arange(1,100,10)\n",
        "    param_grid = {'n_neighbors': nn}\n",
        "\n",
        "    gridcv = sklearn.model_selection.GridSearchCV(clf, param_grid, verbose=1, cv=3)\n",
        "    gridcv.fit(X_train, y_train)\n",
        "    y_pred = gridcv.best_estimator_.predict(X_test)\n",
        "    y_scores = gridcv.best_estimator_.predict_proba(X_test)[:,1]\n",
        "    print(\"best parameters:\", gridcv.best_params_)\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedKNNbase.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFNJ1livVQpd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhfhXc1_VP9A"
      },
      "source": [
        "def AdaBoost(X_train,y_train,X_test,y_test):\n",
        "   # dt_stump = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1)\n",
        "    dt_stump = DecisionTreeClassifier()\n",
        "    dt_stump.fit(X_train, y_train)\n",
        "    dt_stump_err = 1.0 - dt_stump.score(X_test, y_test)\n",
        "\n",
        "    clf = ensemble.AdaBoostClassifier(base_estimator=dt_stump,learning_rate=0.1, algorithm='SAMME')\n",
        "    clf= clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    #y_pred = clf.predict(X_test)\n",
        "    y_scores = clf.predict_proba(X_test)[:,1]\n",
        "    print(\"best parameters:\", gridcv.best_params_)\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedABbase.txt', y_pred, fmt='%01d')\n",
        "\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_tg-y9LMdIh"
      },
      "source": [
        "def GBDT(X_train,y_train,X_test,y_test):\n",
        "    n_estimators = [10,50,100]\n",
        "    learning_rate = [0.01,0.1,1]\n",
        "    max_depth=[1,5,10]\n",
        "    param_grid = {'n_estimators': n_estimators, 'learning_rate': learning_rate,'max_depth':max_depth}\n",
        "\n",
        "    clf = ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=seed)\n",
        "    #clf=clf.fit(X_train, y_train)\n",
        "\n",
        "    gridcv = sklearn.model_selection.GridSearchCV(clf, param_grid, verbose=1, cv=3)\n",
        "    gridcv.fit(X_train, y_train)\n",
        "    y_pred = gridcv.best_estimator_.predict(X_test)\n",
        "    y_scores = gridcv.best_estimator_.predict_proba(X_test)[:,1]\n",
        "    print(\"best parameters:\", gridcv.best_params_)\n",
        "    np.savetxt('/content/drive/My Drive/Data/Result/predictedBGDTbase.txt', y_pred, fmt='%01d')\n",
        "    return evaluate(y_test,y_pred,y_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtCNwKgzVPlz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNE6sbMNnGjM",
        "outputId": "1631069c-9b21-4ef5-e44c-4848f94bef11"
      },
      "source": [
        "print(\"NB training\")\n",
        "a1= Gaussian_NB(traindata,trainlabel,testdata,testlabel)\n",
        "print(a1)\n",
        "#print(\"XG Boost training\")\n",
        "#a2=xgboost(traindata,trainlabel,testdata,testlabel)\n",
        "#print(a2)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB training\n",
            "[0.6851941747572815, 0.7082027168234065, 0.9377378069872017, 0.8069653222205686, 0.5162451073573919]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJUBXhGMCuLn",
        "outputId": "d8ba4ab8-154f-4964-955c-b218aaca5de7"
      },
      "source": [
        "print(\"LR training\")\n",
        "a2=LogisticRegression(traindata,trainlabel,testdata,testlabel)\n",
        "print(a2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.4475728155339806, 0.8078078078078078, 0.27914216534071257, 0.4149100257069409, 0.5924298888922975]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8TvswtEnSDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49df0207-e8fd-4978-d161-384389a8ed73"
      },
      "source": [
        "print(\"MLP training\")\n",
        "a3=MLP(traindata,trainlabel,testdata,testlabel)\n",
        "print(a3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP training\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   33.7s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   33.7s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters: {'alpha': 0.0001, 'hidden_layer_sizes': (10, 5, 3)}\n",
            "[0.4524271844660194, 0.7883742052679382, 0.30024213075060535, 0.4348697394789579, 0.557925905119533]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqQ3iN7vC4jD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2448e15d-4a38-41e9-d6d6-77e586bc09e7"
      },
      "source": [
        "print(\"RF training\")\n",
        "a5=RandomForest(traindata,trainlabel,testdata,testlabel)\n",
        "print(a5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF training\n",
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  6.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  6.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters: {'max_depth': 1, 'n_estimators': 21}\n",
            "[0.38859223300970874, 0.9366197183098591, 0.13801452784503632, 0.24057883629785953, 0.6300803340464318]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YooFWaArDAO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c719ee-c8e8-4d8f-ca88-89fb490b4a06"
      },
      "source": [
        "print(\"DT training\")\n",
        "a6=CART(traindata,trainlabel,testdata,testlabel)\n",
        "print(a6)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT training\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    6.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters: {'max_depth': 1}\n",
            "[0.38859223300970874, 0.9366197183098591, 0.13801452784503632, 0.24057883629785953, 0.5580227236458705]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9geTZf-VSz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c95a705-4f64-4850-f74c-b3fc91c45370"
      },
      "source": [
        "print(\"SVM training\")\n",
        "a4= SVM(traindata,trainlabel,testdata,testlabel)\n",
        "print(a4)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM training\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  2.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best parameters: {'C': 1.0, 'gamma': 0.1}\n",
            "[0.4186893203883495, 0.824607329842932, 0.2179176755447942, 0.3447332421340629, 0.5737871157620279]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU-tThEKnesD"
      },
      "source": [
        "\n",
        "Result = ['a1','a2', 'a3','a4','a5','a6']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYIVQnkLneQ7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c181F-O4Xa_6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkBmi1fJXbnI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "a0ba1884-5a56-4ddf-80d7-340ef12f40c9"
      },
      "source": [
        "print(\"Naive_bayes\")\n",
        "print(\"[accuracy,precision,recall,f1,auc]\")\n",
        "print('a1')\n",
        "\n",
        "print(\"NB training\")\n",
        "a2=Gaussian_NB(traindata,trainlabel,testdata,testlabel)\n",
        "print(a2)\n",
        "\n",
        "print(\"LogisticRegression\")\n",
        "print(\"[accuracy,precision,recall,f1,auc]\")\n",
        "print(a3)\n",
        "\n",
        "print(\"SVM\")\n",
        "print(\"[accuracy,precision,recall,f1,auc]\")\n",
        "print(a4)\n",
        "\n",
        "\n",
        "print(\"MLP\")\n",
        "print(\"[accuracy,precision,recall,f1,auc]\")\n",
        "print(a5)\n",
        "\n",
        "print(\"RandomForest\")\n",
        "print(\"[accuracy,precision,recall,f1,auc]\")\n",
        "print(a6)\n",
        "\n",
        "print(\"CART\")\n",
        "print(\"[accuracy,precision,recall,f1,auc]\")\n",
        "print(a7)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive_bayes\n",
            "[accuracy,precision,recall,f1,auc]\n",
            "a1\n",
            "NB training\n",
            "[0.6851941747572815, 0.7082027168234065, 0.9377378069872017, 0.8069653222205686, 0.5162451073573919]\n",
            "LogisticRegression\n",
            "[accuracy,precision,recall,f1,auc]\n",
            "[0.4524271844660194, 0.7883742052679382, 0.30024213075060535, 0.4348697394789579, 0.557925905119533]\n",
            "SVM\n",
            "[accuracy,precision,recall,f1,auc]\n",
            "[0.4186893203883495, 0.824607329842932, 0.2179176755447942, 0.3447332421340629, 0.5737871157620279]\n",
            "MLP\n",
            "[accuracy,precision,recall,f1,auc]\n",
            "[0.38859223300970874, 0.9366197183098591, 0.13801452784503632, 0.24057883629785953, 0.6300803340464318]\n",
            "RandomForest\n",
            "[accuracy,precision,recall,f1,auc]\n",
            "[0.38859223300970874, 0.9366197183098591, 0.13801452784503632, 0.24057883629785953, 0.5580227236458705]\n",
            "CART\n",
            "[accuracy,precision,recall,f1,auc]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6ebf94f967df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CART\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[accuracy,precision,recall,f1,auc]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'a7' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsbtDWOJYIGQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfD3aDczYHLw"
      },
      "source": [
        "def tsneShow(X,y,Xt,yt):\n",
        "    yys = np.array(y)\n",
        "    yyt = np.array(yt)\n",
        "    for i in range(0, yyt.size):\n",
        "        if yyt[i] == 0:\n",
        "            yyt[i] = 2\n",
        "        elif yyt[i] == 1:\n",
        "            yyt[i] = 3\n",
        "\n",
        "    H = np.vstack((X, Xt))\n",
        "    Y = np.concatenate((yys, yyt), axis=0)\n",
        "\n",
        "    pca = PCA().fit_transform(H)\n",
        "    tsne = TSNE(n_components=2, learning_rate=100).fit_transform(H)\n",
        "\n",
        "    markers = ('.')\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    # plt.subplot(121)\n",
        "    plt.scatter(tsne[:, 0], tsne[:, 1], c=Y, marker=markers[0], cmap=plt.cm.gist_rainbow)\n",
        "\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXh7cOoqYG4n"
      },
      "source": [
        ""
      ]
    }
  ]
}